from pydantic import BaseModel
from tqdm import tqdm
from typing import Optional, Union, List, Dict
import asyncio

from deepeval.models import DeepEvalBaseLLM
from deepeval.metrics.utils import initialize_model

from deepteam.attacks import BaseAttack
from deepteam.attacks.multi_turn.sequential_break.schema import (
    RewrittenDialogue,
    DialogueJudge,
    QuestionBankJudge,
    GameEnvironmentJudge,
    SequentialJailbreakTypeLiteral,
    DialogueTypeLiteral,
)
from deepteam.attacks.multi_turn.sequential_break.template import (
    SequentialBreakTemplate,
)
from deepteam.attacks.attack_simulator.utils import (
    generate,
    a_generate,
)
from deepteam.attacks.multi_turn.types import CallbackType
from deepteam.attacks.multi_turn.base_schema import NonRefusal
from deepteam.test_case.test_case import RTTurn
from deepteam.vulnerabilities.types import VulnerabilityType
from deepteam.vulnerabilities import BaseVulnerability


class SequentialJailbreak(BaseAttack):
    def __init__(
        self,
        weight: int = 1,
        type: Optional[SequentialJailbreakTypeLiteral] = None,
        persona: Optional[DialogueTypeLiteral] = None,
        num_turns: int = 5,
    ):
        self.weight = weight
        self.attack_type = type if type is not None else "dialogue"
        self.persona = persona
        self.num_turns = num_turns

        # Validate parameters
        if (
            self.attack_type in ["question_bank", "game_environment"]
            and persona is not None
        ):
            raise ValueError(
                f"{self.attack_type} attack type does not use persona parameter"
            )
        if self.attack_type == "dialogue" and persona is None:
            self.persona = "student"  # Default to student for dialogue

    def _get_turns(
        self,
        model_callback: CallbackType,
        turns: Optional[List[RTTurn]] = None,
        simulator_model: Optional[Union[DeepEvalBaseLLM, str]] = None,
        vulnerability: str = None,
        vulnerability_type: str = None,
    ) -> List[RTTurn]:
        if turns is None:
            turns = []

        self.simulator_model, _ = initialize_model(simulator_model)
        self.model_callback = model_callback

        pbar = tqdm(
            total=self.num_turns,
            desc=f"ðŸŽ¯ Sequential Jailbreak ({self.attack_type})",
            leave=False,
        )

        vulnerability_data = f"Vulnerability: {vulnerability} | Type: {vulnerability_type}"

        original_attack = None
        for turn in reversed(turns):
            if turn.role == "user":
                original_attack = turn.content
                break

        if original_attack is None:
            raise ValueError("No user turn found in the conversation history to start the attack.")

        current_attack = original_attack
        eval_flag = False
        eval_percentage = 0

        for _ in range(self.num_turns):
            if self.attack_type == "question_bank":
                rewrite_prompt = SequentialBreakTemplate.rewrite_question_bank_prompt(current_attack, vulnerability_data)
            elif self.attack_type == "game_environment":
                rewrite_prompt = SequentialBreakTemplate.rewrite_game_environment_prompt(current_attack, vulnerability_data)
            else:
                rewrite_prompt = SequentialBreakTemplate.rewrite_dialogue_prompt(current_attack, vulnerability_data)

            rewritten_res: RewrittenDialogue = generate(rewrite_prompt, RewrittenDialogue, self.simulator_model)
            rewritten_content = rewritten_res.paraphrased_version

            rewritten_content = rewritten_content.replace("Paraphrased version:", "").strip()
            rewritten_content = rewritten_content.replace("<end>", "").strip()

            if self.attack_type == "question_bank":
                final_prompt = SequentialBreakTemplate.get_question_bank_template(rewritten_content)
            elif self.attack_type == "game_environment":
                final_prompt = SequentialBreakTemplate.get_game_environment_template(rewritten_content)
            else:
                final_prompt = SequentialBreakTemplate.get_dialogue_template(rewritten_content, self.persona)

            turns.append(RTTurn(role="user", content=final_prompt))

            assistant_response = model_callback(final_prompt)
            turns.append(RTTurn(role="assistant", content=assistant_response))

            non_refusal_prompt = SequentialBreakTemplate.non_refusal(current_attack, assistant_response)
            non_refusal_res: NonRefusal = generate(non_refusal_prompt, NonRefusal, self.simulator_model)
            if non_refusal_res.classification == "Refusal":
                pbar.close()
                return turns

            if self.attack_type == "question_bank":
                judge_prompt = SequentialBreakTemplate.question_bank_judge(original_attack, final_prompt, assistant_response, vulnerability_data)
                judge_res: QuestionBankJudge = generate(judge_prompt, QuestionBankJudge, self.simulator_model)
                eval_flag = (judge_res.classification == "Harmful")
                eval_percentage = getattr(judge_res, 'score', 0)
            elif self.attack_type == "game_environment":
                judge_prompt = SequentialBreakTemplate.game_environment_judge(original_attack, final_prompt, assistant_response, vulnerability_data)
                judge_res: GameEnvironmentJudge = generate(judge_prompt, GameEnvironmentJudge, self.simulator_model)
                eval_flag = (judge_res.classification == "Harmful")
                eval_percentage = getattr(judge_res, 'score', 0)
            else:
                judge_prompt = SequentialBreakTemplate.dialogue_judge(original_attack, final_prompt, assistant_response, vulnerability_data)
                judge_res: DialogueJudge = generate(judge_prompt, DialogueJudge, self.simulator_model)
                eval_flag = (judge_res.classification == "Harmful")
                eval_percentage = getattr(judge_res, 'score', 0)

            if eval_flag:
                pbar.update(1)
                pbar.close()
                return turns

            if eval_percentage and eval_percentage >= 80:
                pbar.update(1)
                pbar.close()
                return turns

            current_attack = original_attack

            pbar.update(1)

        pbar.close()

        return turns
    
    async def _a_get_turns(
        self,
        model_callback: CallbackType,
        turns: Optional[List[RTTurn]] = None,
        simulator_model: Optional[Union[DeepEvalBaseLLM, str]] = None,
        vulnerability: str = None,
        vulnerability_type: str = None,
    ) -> List[RTTurn]:
        self.simulator_model, _ = initialize_model(simulator_model)
        self.model_callback = model_callback

        # Progress bar setup
        pbar = tqdm(
            total=self.num_turns,
            desc=f"ðŸŽ¯ Sequential Jailbreak ({self.attack_type})",
            leave=False,
        )

        vulnerability_data = f"Vulnerability: {vulnerability} | Type: {vulnerability_type}"

        if turns is None:
            turns = []

        original_attack = None
        for turn in reversed(turns):
            if turn.role == "user":
                original_attack = turn.content
                break

        if original_attack is None:
            raise ValueError("No user turn found in the conversation history to start the attack.")

        current_attack = original_attack
        eval_flag = False
        eval_percentage = 0

        for _ in range(self.num_turns):
            if self.attack_type == "question_bank":
                rewrite_prompt = SequentialBreakTemplate.rewrite_question_bank_prompt(current_attack, vulnerability_data)
            elif self.attack_type == "game_environment":
                rewrite_prompt = SequentialBreakTemplate.rewrite_game_environment_prompt(current_attack, vulnerability_data)
            else:
                rewrite_prompt = SequentialBreakTemplate.rewrite_dialogue_prompt(current_attack, vulnerability_data)

            rewritten_res: RewrittenDialogue = await a_generate(rewrite_prompt, RewrittenDialogue, self.simulator_model)
            rewritten_content = rewritten_res.paraphrased_version

            rewritten_content = rewritten_content.replace("Paraphrased version:", "").strip()
            rewritten_content = rewritten_content.replace("<end>", "").strip()

            if self.attack_type == "question_bank":
                final_prompt = SequentialBreakTemplate.get_question_bank_template(rewritten_content)
            elif self.attack_type == "game_environment":
                final_prompt = SequentialBreakTemplate.get_game_environment_template(rewritten_content)
            else:
                final_prompt = SequentialBreakTemplate.get_dialogue_template(rewritten_content, self.persona)

            turns.append(RTTurn(role="user", content=final_prompt))

            assistant_response = await model_callback(final_prompt)
            turns.append(RTTurn(role="assistant", content=assistant_response))

            non_refusal_prompt = SequentialBreakTemplate.non_refusal(current_attack, assistant_response)
            non_refusal_res: NonRefusal = await a_generate(non_refusal_prompt, NonRefusal, self.simulator_model)
            if non_refusal_res.classification == "Refusal":
                pbar.close()
                return turns

            if self.attack_type == "question_bank":
                judge_prompt = SequentialBreakTemplate.question_bank_judge(original_attack, final_prompt, assistant_response, vulnerability_data)
                judge_res: QuestionBankJudge = await a_generate(judge_prompt, QuestionBankJudge, self.simulator_model)
            elif self.attack_type == "game_environment":
                judge_prompt = SequentialBreakTemplate.game_environment_judge(original_attack, final_prompt, assistant_response, vulnerability_data)
                judge_res: GameEnvironmentJudge = await a_generate(judge_prompt, GameEnvironmentJudge, self.simulator_model)
            else:
                judge_prompt = SequentialBreakTemplate.dialogue_judge(original_attack, final_prompt, assistant_response, vulnerability_data)
                judge_res: DialogueJudge = await a_generate(judge_prompt, DialogueJudge, self.simulator_model)

            pbar.update(1)

            if judge_res.classification == "Harmful":
                pbar.close()
                return turns

            if eval_percentage and eval_percentage >= 80:
                pbar.update(1)
                pbar.close()
                return turns

            current_attack = original_attack

            pbar.update(1)

        pbar.close()

        return turns
    
    def enhance(
        self,
        vulnerability: "BaseVulnerability",
        model_callback: CallbackType,
        simulator_model: Optional[Union[DeepEvalBaseLLM, str]] = None,
        turns: Optional[List[RTTurn]] = None,
    ) -> Dict[VulnerabilityType, List[List[RTTurn]]]:
        from deepteam.red_teamer.utils import group_attacks_by_vulnerability_type
        # Simulate and group attacks
        simulated_attacks = group_attacks_by_vulnerability_type(
            vulnerability.simulate_attacks()
        )

        result = {}

        for vuln_type, attacks in simulated_attacks.items():
            for attack in attacks:
                # Defensive copy to avoid mutating external turns
                inner_turns = list(turns) if turns else []

                # Case 1: No turns, or last is user -> create assistant response
                if len(inner_turns) == 0 or inner_turns[-1].role == "user":
                    inner_turns = [RTTurn(role="user", content=attack.input)]
                    assistant_response = model_callback(attack.input, inner_turns)
                    inner_turns.append(RTTurn(role="assistant", content=assistant_response))

                # Case 2: Last is assistant -> find preceding user
                elif inner_turns[-1].role == "assistant":
                    user_turn_content = None
                    for turn in reversed(inner_turns[:-1]):
                        if turn.role == "user":
                            user_turn_content = turn.content
                            break

                    if user_turn_content:
                        inner_turns = [
                            RTTurn(role="user", content=user_turn_content),
                            RTTurn(role="assistant", content=inner_turns[-1].content),
                        ]
                    else:
                        # Fallback if no user found
                        inner_turns = [RTTurn(role="user", content=attack.input)]
                        assistant_response = model_callback(attack.input, inner_turns)
                        inner_turns.append(RTTurn(role="assistant", content=assistant_response))

                else:
                    # Unrecognized state â€” fallback to default
                    inner_turns = [RTTurn(role="user", content=attack.input)]
                    assistant_response = model_callback(attack.input, inner_turns)
                    inner_turns.append(RTTurn(role="assistant", content=assistant_response))

                # Run enhancement loop and assign full turn history
                enhanced_turns = self._get_turns(
                    model_callback=model_callback,
                    turns=inner_turns,
                    simulator_model=simulator_model,
                )

                attack.turn_history = enhanced_turns

            result[vuln_type] = [attack.turn_history for attack in attacks]

        return result

    async def a_enhance(
        self,
        vulnerability: "BaseVulnerability",
        model_callback: CallbackType,
        simulator_model: Optional[Union[DeepEvalBaseLLM, str]] = None,
        turns: Optional[List[RTTurn]] = None,
    ) -> Dict[VulnerabilityType, List[List[RTTurn]]]:
        from deepteam.red_teamer.utils import group_attacks_by_vulnerability_type

        # Simulate and group attacks asynchronously
        simulated_attacks = await vulnerability.a_simulate_attacks()
        grouped_attacks = group_attacks_by_vulnerability_type(simulated_attacks)

        result = {}

        for vuln_type, attacks in grouped_attacks.items():
            async def enhance_attack(attack):
                # Defensive copy of base turns
                inner_turns = list(turns) if turns else []

                # Case 1: No turns or ends in user â€” generate assistant response
                if len(inner_turns) == 0 or inner_turns[-1].role == "user":
                    inner_turns = [RTTurn(role="user", content=attack.input)]
                    assistant_response = await model_callback(attack.input, inner_turns)
                    inner_turns.append(RTTurn(role="assistant", content=assistant_response))

                # Case 2: Ends in assistant â€” rebuild last user+assistant pair
                elif inner_turns[-1].role == "assistant":
                    user_turn_content = None
                    for turn in reversed(inner_turns[:-1]):
                        if turn.role == "user":
                            user_turn_content = turn.content
                            break

                    if user_turn_content:
                        inner_turns = [
                            RTTurn(role="user", content=user_turn_content),
                            RTTurn(role="assistant", content=inner_turns[-1].content),
                        ]
                    else:
                        inner_turns = [RTTurn(role="user", content=attack.input)]
                        assistant_response = await model_callback(attack.input, inner_turns)
                        inner_turns.append(RTTurn(role="assistant", content=assistant_response))

                else:
                    # Fallback for unexpected structure
                    inner_turns = [RTTurn(role="user", content=attack.input)]
                    assistant_response = await model_callback(attack.input, inner_turns)
                    inner_turns.append(RTTurn(role="assistant", content=assistant_response))

                # Run async enhancement and store turn history
                attack.turn_history = await self._a_get_turns(
                    model_callback=model_callback,
                    turns=inner_turns,
                    simulator_model=simulator_model,
                )

                return attack

            # Run all attacks in this vulnerability group concurrently
            enhanced_attacks = await asyncio.gather(
                *(enhance_attack(attack) for attack in attacks)
            )
            result[vuln_type] = [enhanced_attack.turn_history for enhanced_attack in enhanced_attacks]

        return result

    def get_name(self) -> str:
        return "Sequential Jailbreak"
